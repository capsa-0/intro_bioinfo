{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mPp1Dtq9xu8"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1cwPX7BgVIwtG7Rpd9FQGdfOxaVrgaR59\" alt=\"Descripción\" width=\"178\">\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1bLJqVtTvaYSS46sJ_VSVmY7j8QgfhAln\" alt=\"Descripción\" width=\"100\">\n",
    "</center>\n",
    "\n",
    "---\n",
    "# **Bioinformática 2025**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_2Mrg0f9mLS"
   },
   "source": [
    "# TP Nº3: BLAST\n",
    "\n",
    "El algoritmo BLAST (Basic Local Alignment Search Tool) permite realizar búsquedas rápidas de secuencias sobre bases de datos biológicas (de secuencias). Esto lo hace mediante una heurística, la cual consiste en generar pequeñas secuencias semilla a partir de la consulta inicial, alinearlas contra cada una de las secuencias en la base de datos e ir extendiendo en medida que las correspondencias tengan un elevado score. Llamaremos query a la secuencia que se quiere buscar y db a la base sobre la cual se realiza dicha búsqueda. La eficiencia del método está en evitar la comparación exhaustiva entre el query entero y la base de datos, sino que compara los pequeños fragmentos o words y luego extiende los matchs hasta que logren superar un umbral determinado.\n",
    "\n",
    "BLAST en realidad son 4 algoritmos (como usted sabe de IBM):\n",
    "  - `blastn`: query -> nu db -> nu\n",
    "  - `blastp`: query -> prot db -> prot\n",
    "  - `blastx`: query -> nucleótido , db -> prot\n",
    "  - `tblastn`:  query -> prot, db -> nucl\n",
    "\n",
    "\n",
    "Los resultados son las correspondencias de la query con una dada entrada de la db, a la que llamaremos hit, métricas de esa correspondencia (identidad, cobertura, gaps) y dependiendo de lo solicitado, el alineamiento entre las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq6t4B3V9mLV"
   },
   "source": [
    "Instale BLAST con el comando:\n",
    "```bash\n",
    "sudo apt install ncbi-blast+\n",
    "o\n",
    "colab:\n",
    "!sudo apt install ncbi-blast+\n",
    "```\n",
    "o también, si tiene levantado un ambiente de conda, puede hacer:\n",
    "```bash\n",
    "conda install -c bioconda blast\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYZwRcfB9mLX"
   },
   "source": [
    "### ¿Por qué usar una ejecución local de BLAST si hay tantos buscadores de secuencia en la web?\n",
    "\n",
    "En general, si queremos buscar secuencias de a una, o analizar un resultado corto, es siempre mejor usar una herramienta online. Pero si queremos buscar en muchas muestras, con muchos parámetros distintos,  en bases distintas a las que ofrecen las distintas páginas, o dentro de un pipeline de análisis más complejo, conviene correr las búsquedas localmente.\n",
    "\n",
    "Blast ofrece varios formatos de salida, pero aquí marcaremos los 2 más utilizados:\n",
    "\n",
    "a) separado por tab (tsv),\n",
    "\n",
    "y b) salida de texto.\n",
    "\n",
    "La primera es muy útil para analizarla con pandas y permite elegir las columnas del archivo (incluso se puede pedir el alineamiento, cosa que no hace por defecto).\n",
    "\n",
    "La salida de texto, es la más tradicional y su objetivo es que pueda ser comprendida por una persona. Por otro lado, casi todos los formatos se pueden leer usando biopython, cosa que veremos al final de la práctica.\n",
    "Lo que haremos ahora es descargar unos archivos y trabajar con BLAST sobre los mismos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMICRE7i9mLY"
   },
   "source": [
    "## 1. **Descargar archivos y preparar la base de datos:**\n",
    "   - Buscar secuencias de las proteínas: `drrA`, `map2k7` y `ndk` en la base de datos **vfdbB**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlCEjxMn-8KF"
   },
   "source": [
    "\n",
    "## 2. **Comandos a utilizar:**\n",
    "\n",
    "   ```bash\n",
    "   # Descargamos los archivos\n",
    "   wget -O drrA.faa \"https://rest.uniprot.org/uniprotkb/Q29ST3.fasta\"\n",
    "   wget \"http://www.mgc.ac.cn/VFs/Down/VFDB_setB_pro.fas.gz\"\n",
    "\n",
    "   # Descomprimimos el archivo\n",
    "   gunzip VFDB_setB_pro.fas.gz\n",
    "\n",
    "   # Generamos el índice para acelerar las búsquedas\n",
    "   makeblastdb -dbtype prot -in VFDB_setB_pro.fas\n",
    "\n",
    "   # Realizamos la búsqueda (reemplace drrA por los archivos fasta correspondientes)\n",
    "   blastp -query drrA.faa -db VFDB_setB_pro.fas -evalue 1e-5\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ```bash\n",
    "   #Descargamos los archivos que faltan y blasteamos\n",
    "    wget -O mp2k7.faa \"hhttps://rest.uniprot.org/uniprotkb/O14733.fasta\"\n",
    "    wget -O ndk.faa \"https://rest.uniprot.org/uniprotkb/Q13232.fasta\"\n",
    "\n",
    "    blastp -query mp2k7.faa -db VFDB_setB_pro.fas -evalue 1e-5\n",
    "    blastp -query ndk.faa -db VFDB_setB_pro.fas -evalue 1e-5\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK6MWlU5-_I9"
   },
   "source": [
    "\n",
    "## 3. **Parámetros útiles en BLAST:**\n",
    "\n",
    "   - `-num_threads`: Número de núcleos para paralelización.\n",
    "   - `-qcov_hsp_perc`: Cobertura mínima de la query.\n",
    "   - `-evalue`: Limita los hits (el valor por defecto es 10, lo que puede traer resultados no deseados).\n",
    "   - `-outfmt`: Define el formato de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtIZhpcV9mLZ"
   },
   "source": [
    "### Ejercicio 1\n",
    "Repita la misma búsqueda con el parámetro `-outfmt 6` y visualice las columnas. Investigue en la documentación de BLAST cómo incluir el alineamiento en las columnas. (http://www.metagenomics.wiki/tools/blast/blastn-output-format-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    blastp -query datasets/drrA.faa -db datasets/VFDB_setB_pro.fas -evalue 1e-5 -outfmt \"6 qseqid sseqid pident length mismatch gapopen evalue bitscore qlen slen\" -out \"blast_crudos/drrAvsVFDB_fmt6\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lslW6Hlb_sd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp|Q29ST3|DRRA_LEGPN\tVFG018236(gb|WP_010948166)\t100.000\t647\t0\t0\t0.0\t1333\t647\t647\n",
      "\n",
      "sp|Q29ST3|DRRA_LEGPN\tVFG018237(gb|WP_041173820)\t99.382\t647\t4\t0\t0.0\t1328\t647\t647\n",
      "\n",
      "sp|Q29ST3|DRRA_LEGPN\tVFG041262(gb|WP_010946835)\t27.907\t129\t86\t2\t4.44e-09\t58.5\t647\t322\n",
      "\n",
      "sp|Q29ST3|DRRA_LEGPN\tVFG045589(gb|WP_010948303)\t38.272\t81\t50\t0\t1.65e-06\t50.8\t647\t434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"blast_crudos/drrAvsVFDB_fmt6\",'r') as file:\n",
    "    for linea in file.readlines():\n",
    "        print(linea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DRmNNsK_29M"
   },
   "source": [
    "Ahora, vamos a procesar la salida de texto de BLAST utilizando el paquete **Bio.SearchIO** de la librería **Biopython** (que usted ya utilizó previamente). Para entender las estructuras de datos que genera Biopython al leer los *hits*, lea detenidamente la sección 8 de la documentación (la misma estructura es utilizada para Hmmer, y lo veremos en la próxima guía).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIovHdKt9mLa"
   },
   "source": [
    "\n",
    "### Ejercicio 2\n",
    "\n",
    "Como ejercicio, vamos a buscar **TODOS** factores de virulencia de la base de datos VFDB sobre el proteoma de *Staphylococcus aureus N315* (send to -> Coding Sequences -> Fasta Protein) (https://www.ncbi.nlm.nih.gov/nuccore/NC_002745.2/). Primero ejecute BLAST, con el formato por defecto (NO use `outfmt`).\n",
    "\n",
    "Almacene el resultado en un archivo y para analizar el resultado, complete el script (o código de Python) a partir del que mostramos más abajo, para generar una tabla que muestre las siguientes columnas: *query*, *hit*, *cobertura de la query*, *cobertura del hit*, *identidad* y de qué especie es la proteína *hit*. También debe indicar si una de las proteínas buscadas NO está.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "\n",
    "El comando utilizado para blastear fue \n",
    "``` bash\n",
    "blastp -query datasets/VFDB_setB_pro.fas -db datasets/proteome_N315.fas -out blast_crudos/EJ2_blastp_VFDBvsN315_fmt5_cv70.xml -outfmt 5 -evalue 1e-5 -qcov_hsp_perc 70\n",
    "```\n",
    "\n",
    "Elegimos -outfmt 5 porque incluye las querys sin hits y los archivos .xml son fácilmente parseables con SearchIO de biopython. No se pudo parsear el archivo generado con el formato de salida por defecto de blastp con SearchIO (Unknown format 'blast-text'). También podría usarse -outfmt \"6...\", pasando como parámetros solamente la información que queremos extraer\n",
    "\n",
    "con -evalue 1e-5 -qcov_hsp_perc 70 definimos el límite del e-value como $10^{-5}$ y el porcentaje de cobertura mínimo del hit como 70%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VFDB_setB_pro vs Proteome_N315\n",
      "                      query_id                                hit_id  \\\n",
      "15  VFG037196(gb|YP_005796961)                                     0   \n",
      "16  VFG037198(gb|WP_001081736)                                     0   \n",
      "17  VFG037203(gb|WP_000079188)  NC_002745.2_prot_WP_000571549.1_2043   \n",
      "18  VFG037203(gb|WP_000079188)  NC_002745.2_prot_WP_001270822.1_1239   \n",
      "19  VFG037201(gb|WP_000079186)  NC_002745.2_prot_WP_000571549.1_2043   \n",
      "\n",
      "    cobertura_query  cobertura_hit  porcentaje_identidad  \n",
      "15         0.000000       0.000000              0.000000  \n",
      "16         0.000000       0.000000              0.000000  \n",
      "17        72.828096      79.757085             20.558376  \n",
      "18        73.937153      81.135903             21.250000  \n",
      "19        72.828096      79.757085             20.558376  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SearchIO\n",
    "\n",
    "# Defino una función para los ejercicios 2, 3 y 4. Recibe una salida de blast parseada por SearchIO y devuelve un dataframe\n",
    "# de pandas cuyas columnas son query, hit, cobertura de la query, cobertura del hit, identidad. Como en el punto 4 se piden variantes\n",
    "# se incluye un parámetro include_variants \n",
    "def summarize_blastp(blast_results,include_variants=0):\n",
    "    \n",
    "    # Inicializo listas que contendrán los parámetros importantes del blast y serán las columnas del dataframe. \n",
    "    id_querys=[]\n",
    "    id_hits=[]\n",
    "    coverage_querys=[]\n",
    "    coverage_hits=[]\n",
    "    p_ident=[]\n",
    "    variants=[]\n",
    "\n",
    "    # Itero sobre cada secuencia query de VFDB\n",
    "    for query in blast_results:\n",
    "        query_len=query.seq_len\n",
    "        # Compruebo que la query tenga hits\n",
    "        if query.hits:\n",
    "            # Itero sobre cada hit, extrayendo la ID de la secuencia subject y el nombre de la proteína.\n",
    "            for hit in query.hits:\n",
    "                hit_len=hit.seq_len\n",
    "                hit_id=hit.id.split('|')[1] if '|' in hit.id else hit.id\n",
    "                # Itero sobre cada hsp (high scoring-sequence pair) y añado a las listas los datos del\n",
    "                # hsp que quiero en las columnas del dataframe. (Lo que llamo coverage_hits es en realidad\n",
    "                # la covertura de cada hsp)\n",
    "                for hsp in hit.hsps:\n",
    "                    id_querys.append(query.id)\n",
    "                    id_hits.append(hit_id)\n",
    "                    coverage_querys.append((hsp.aln_span/query_len)*100)\n",
    "                    coverage_hits.append((hsp.aln_span/hit_len)*100)\n",
    "                    p_ident.append((hsp.ident_num / hsp.aln_span) * 100)\n",
    "\n",
    "                    if include_variants:\n",
    "                        variants.append(find_variants(hsp.query.seq,hsp.hit.seq))\n",
    "\n",
    "        # Si no se encuentran hits para la query añado su ID y agrego 0 al resto de listas.         \n",
    "        else:  \n",
    "            nule_value = 0\n",
    "            id_querys.append(query.id)\n",
    "            id_hits.append(nule_value) \n",
    "            coverage_querys.append(nule_value)\n",
    "            coverage_hits.append(nule_value)\n",
    "            p_ident.append(nule_value)\n",
    "            if include_variants:\n",
    "                variants.append(nule_value)\n",
    "\n",
    "    # Genero el dataframe \n",
    "    summary_blastp = pd.DataFrame({\n",
    "        \"query_id\": id_querys,\n",
    "        \"hit_id\": id_hits,\n",
    "        \"cobertura_query\": coverage_querys,\n",
    "        \"cobertura_hit\": coverage_hits,\n",
    "        \"porcentaje_identidad\": p_ident\n",
    "    })\n",
    "\n",
    "    if include_variants:\n",
    "        summary_blastp['variantes'] = variants\n",
    "\n",
    "    return summary_blastp\n",
    "\n",
    "aa_code = {\n",
    "        'A': 'Ala', 'R': 'Arg', 'N': 'Asn', 'D': 'Asp', 'C': 'Cys',\n",
    "        'E': 'Glu', 'Q': 'Gln', 'G': 'Gly', 'H': 'His', 'I': 'Ile',\n",
    "        'L': 'Leu', 'K': 'Lys', 'M': 'Met', 'F': 'Phe', 'P': 'Pro',\n",
    "        'S': 'Ser', 'T': 'Thr', 'W': 'Trp', 'Y': 'Tyr', 'V': 'Val'\n",
    "    }\n",
    "\n",
    "def find_variants(q,s):\n",
    "    global aa_code\n",
    "    variants=''\n",
    "    last_aa,pos='',0\n",
    "    for i,aa in enumerate(s):\n",
    "        if aa in ['X','*'] or q[i] in ['X','*']:\n",
    "            continue\n",
    "        if aa!='-':\n",
    "            last_aa,pos=aa,i+1\n",
    "        if aa != q[i]:\n",
    "            if aa == '-':\n",
    "                prev_aa=s[:i].replace('-','')[-1]\n",
    "                variants+=f'| {aa_code[last_aa]}{pos}_{i+1}ins{aa_code[q[i]]} '\n",
    "            elif q[i] == '-':\n",
    "                variants+=f'| {aa_code[aa]}{i+1}del '\n",
    "            else:\n",
    "                variants+=f'| {aa_code[aa]}{i+1}{aa_code[q[i]]} '\n",
    "    return variants[2:-1]\n",
    "\n",
    "\n",
    "blast_file = 'blast_crudos/EJ2_blastp_VFDBvsN315_fmt5_cv70.xml' \n",
    "blast_results = list(SearchIO.parse(blast_file, \"blast-xml\"))\n",
    "summary=summarize_blastp(blast_results)\n",
    "\n",
    "print(\"VFDB_setB_pro vs Proteome_N315\")\n",
    "# Imprimo algunas lineas para ver la estructura del dataframe\n",
    "print(summary[15:20])\n",
    "\n",
    "# Exporto el dataframe como .tsv\n",
    "summary.to_csv(blast_file + \"_resumen.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7DbZflZ9mLc"
   },
   "source": [
    "\"busqueda.blast\" debe ser el resultado de la búsqueda anterior, pidiendo una cobertura del hit del 70% (investigue el parámetro indicado).\n",
    "\n",
    "Es muy común encontrarse con familias de proteínas, que poseen funciones mal anotadas (por ejemplo el nombre de un gen) y/o representantes cuyas secuencias no son muy distintas, pero a la hora de anotar un genoma, es importante distinguir entre las mismas. Puede usar el *output* de BLAST que quiera, pero recomendamos el formato tabla.\n",
    "\n",
    "Como ejemplo de esto, vamos a usar el ejemplo de las **enterotoxinas**, una familia de proteínas que en nuestra experiencia está bastante mal anotada en las bases secundarias. En [este trabajo](https://pubmed.ncbi.nlm.nih.gov/), hacen un buen trabajo curando secuencias representativas de cada toxina, con lo cual, cuando vemos “buenos hits” de nuestros genes contra ellas, podemos estar seguros de su clasificación. Las secuencias curadas pueden encontrarlas en ese link.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecvt38z5Ayj3"
   },
   "source": [
    "### Ejercicios 3\n",
    "1. Realice un BLAST del proteoma de N315 contra la base de enterotoxinas y desarrolle un script que, levantando esa información, indique cuáles son las enterotoxinas que posee el proteoma. (Posiblemente obtenga varios *hits* para cada proteína)\n",
    "2. Programe algún criterio de decisión en función de la identidad / cobertura. En caso de que más de un hit cumpla las expectativas, indique que encontró más de una proteína.\n",
    "3. Pruebe su código con 2 proteomas al azar de [aquí](https://some.link/) e informar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9n7WZbeAw2x"
   },
   "source": [
    "### Ejercicio 4\n",
    "Al script anterior, agréguele una salida que informe las diferencias / polimorfismos entre la base de datos y la proteína del genoma **query**. Por ejemplo, si en la posición 137 de la referencia (DB) tiene una alanina y la proteína del proteoma tiene una histidina (`Ala137His`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "\n",
    "El comando utilizado para blastear fue \n",
    "\n",
    "```bash\n",
    "blastp -query datasets/proteome_N315.fas -db datasets/curated_enterotoxins.fas -out blast_crudos/EJ3_blastp_N315vsENTEROT_fmt5.xml -outfmt 5 -evalue 1e-5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|11' since the ID was already matched by your query 'lcl|NC_002745.2_prot_SA_RS15135_1527'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000736712.1_1759'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_001236362.1_1760'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|11' since the ID was already matched by your query 'lcl|NC_002745.2_prot_SA_RS15170_1761'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000713847.1_1762'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000821658.1_1763'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_010922839.1_1764'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000034846.1_1895'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000746599.1_1958'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n",
      "f:\\ANACONDA\\envs\\bioinfo\\lib\\site-packages\\Bio\\SearchIO\\BlastIO\\blast_xml.py:342: BiopythonParserWarning: Renaming hit ID 'Gr11/seh-2p' to a BLAST-generated ID 'gnl|BL_ORD_ID|10' since the ID was already matched by your query 'lcl|NC_002745.2_prot_WP_000278088.1_1959'. Your BLAST database may contain duplicate entries.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteome_N315 vs curated_enterotoxins\n",
      "                                    query_id  hit_id  cobertura_query  \\\n",
      "368  lcl|NC_002745.2_prot_WP_000475325.1_369    selx       100.000000   \n",
      "398  lcl|NC_002745.2_prot_WP_000669014.1_399    sely       101.769912   \n",
      "400  lcl|NC_002745.2_prot_WP_000669014.1_399     set        76.106195   \n",
      "417  lcl|NC_002745.2_prot_WP_000769820.1_405  tsst-1        91.341991   \n",
      "432  lcl|NC_002745.2_prot_WP_000673051.1_408  tsst-1       100.440529   \n",
      "\n",
      "     cobertura_hit  porcentaje_identidad  \\\n",
      "368      99.509804             96.059113   \n",
      "398     103.603604             29.130435   \n",
      "400      79.262673             30.232558   \n",
      "417      89.787234             27.014218   \n",
      "432      97.021277             23.245614   \n",
      "\n",
      "                                             variantes  \n",
      "368  Ser24Gly | Ser26Thr | Gly109Asp | Asn160Asp | ...  \n",
      "398  Leu3Ala | Trp4Ser | Phe5Leu | Leu6Ala | Thr8Gl...  \n",
      "400  Ser2Gln | Asp3Gln | Arg5Glu | Glu6Ser | Gly7Gl...  \n",
      "417  Asn1Asp | Leu6Tyr | Asp7Arg | Trp8Tyr | Gly12G...  \n",
      "432  Ser1Ala | Pro2Thr | Leu4Ala | Ala6Gly | Thr7Il...  \n"
     ]
    }
   ],
   "source": [
    "# Defino diccionario para pasar los aminoácidos de código de una letra al de tres\n",
    "aa_code = {\n",
    "        'A': 'Ala', 'R': 'Arg', 'N': 'Asn', 'D': 'Asp', 'C': 'Cys',\n",
    "        'E': 'Glu', 'Q': 'Gln', 'G': 'Gly', 'H': 'His', 'I': 'Ile',\n",
    "        'L': 'Leu', 'K': 'Lys', 'M': 'Met', 'F': 'Phe', 'P': 'Pro',\n",
    "        'S': 'Ser', 'T': 'Thr', 'W': 'Trp', 'Y': 'Tyr', 'V': 'Val'\n",
    "    }\n",
    "\n",
    "# Defino una función que toma una secuencia query y otra subject y busca las variantes, esta función es usada por summarize_blastp\n",
    "def find_variants(q,s):\n",
    "    global aa_code\n",
    "    variants=''\n",
    "    last_aa,pos='',0\n",
    "    for i,aa in enumerate(s):\n",
    "        if aa in ['X','*'] or q[i] in ['X','*']:\n",
    "            continue\n",
    "        if aa!='-':\n",
    "            last_aa,pos=aa,i+1\n",
    "        if aa != q[i]:\n",
    "            if aa == '-':\n",
    "                prev_aa=s[:i].replace('-','')[-1]\n",
    "                variants+=f'| {aa_code[last_aa]}{pos}_{i+1}ins{aa_code[q[i]]} '\n",
    "            elif q[i] == '-':\n",
    "                variants+=f'| {aa_code[aa]}{i+1}del '\n",
    "            else:\n",
    "                variants+=f'| {aa_code[aa]}{i+1}{aa_code[q[i]]} '\n",
    "    return variants[2:-1]\n",
    "\n",
    "\n",
    "\n",
    "blast_file = 'blast_crudos/EJ3_blastp_N315vsENTEROT_fmt5.xml' \n",
    "blast_results = list(SearchIO.parse(blast_file, \"blast-xml\"))\n",
    "\n",
    "# Uso include_variants=1, para que el dataframe incluya las variantes encontradas en cada alineamiento\n",
    "# La función para encontrar variables está definida en auxiliary_functions.py\n",
    "summary = summarize_blastp(blast_results,include_variants=1)\n",
    "\n",
    "#################\n",
    "# La última linea arroja warnings, esto ocurre porque la base de datos de enterotoxinas curadas contiene secuencias distintas con el mismo ID, por ejemplo\n",
    "\n",
    "#>Gr11/seh-2p - truncated NC_017351.1\n",
    "#NIILFFTLLFVLTSYAKAEDLHDKSELSDLALANAYGQYNHPFIKENVISSEIIGEKDLIFRNQGDNGNDLR\n",
    "#VKFASAGLAQNFKNKNVDIYGASFYYKCEKVSENISECLYGGTTLNNEKLEQERVIGANVWVNGIQKET\n",
    "#ELIRTNKKNVTLQELDIKMRKNYLINIEFIIKTVK\n",
    "#>Gr11/seh-2p - fully repaired NC_017351.1\n",
    "#MRKKIRILFXFFTLLFVLTSYAKAEDLHDKSELSDLALANAYGQYNHPFIKENVISSEIIGEKDLIFRNQGD\n",
    "#NGNDLRVKFASAGLAQNFKNKNVDIYGASFYYKCEKVSENISECLYGGTTLNNEKLEQERVIGANVWV\n",
    "#NGIQKETELIRTNKKNVTLQELDIKMRKXLSNKYRIYYKDSEIRKGLIEFDMKTPRDYSFDIYDLKGENDY\n",
    "#EIDKIYEDNKTLKSEDISHIDIYLYTK\n",
    "\n",
    "# En este caso se trata de la misma proteína pero una es la versión truncada. Como \"truncated\" está separada de seh-2p,\n",
    "# al parsear, se toma como ID \"seh-2p\", lo que eleva un warning; Igualmente SearchIO simplemente asigna una nueva ID. \n",
    "# Se podría usar un sufijo de la forma \"_truncated\" en la base de datos (seh-2p_truncated) para solucionar ésto.\n",
    "#################\n",
    "\n",
    "# Parámetros de cobertura e identidad mínimos establecidos \n",
    "min_cov_query = 75\n",
    "min_ident = 0.8\n",
    "\n",
    "# Filtro el dataframe, quedándome solamente con aquellos hits que cumplan los criterios establecidos\n",
    "summary_filtered = summary.loc[\n",
    "    (summary[\"cobertura_query\"] > min_cov_query) &\n",
    "    (summary[\"porcentaje_identidad\"] > min_ident)\n",
    "]\n",
    "print(\"Proteome_N315 vs curated_enterotoxins\")\n",
    "print(summary_filtered[:5])\n",
    "\n",
    "# Exporto el dataframe como .tsv\n",
    "summary_filtered.to_csv(blast_file + \"_resumen_filtrado.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (bioinfo)",
   "language": "python",
   "name": "bioinfo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
